import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.impute import KNNImputer
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    confusion_matrix, ConfusionMatrixDisplay,
    accuracy_score, f1_score, precision_score, recall_score,
    roc_curve, roc_auc_score, log_loss, auc
)
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import fbeta_score
import warnings
warnings.filterwarnings('ignore')

# Import data
url = "https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv"
cols = ["Pregnancies", "Glucose", "BloodPressure", "SkinThickness",
        "Insulin", "BMI", "DiabetesPedigreeFunction", "Age", "Outcome"]
data = pd.read_csv(url, header=None, names=cols)
print("Dataset shape:", data.shape)

# 1. TI·ªÄN X·ª¨ L√ù D·ªÆ LI·ªÜU
print("\n M√¥ t·∫£ th·ªëng k√™ n√¢ng cao:")
desc = data.describe().T
desc["missing"] = data.isnull().sum()
desc["zeros"] = (data == 0).sum()
desc["std/mean"] = desc["std"] / desc["mean"]
print(desc)
plt.figure(figsize=(15, 6))
data.boxplot()
plt.title("Boxplot to√†n b·ªô thu·ªôc t√≠nh (t√¨m outliers)")
plt.xticks(rotation=45)
plt.show()
plt.figure(figsize=(15, 6))
sns.violinplot(data=data)
plt.title("Violin plot c√°c thu·ªôc t√≠nh")
plt.xticks(rotation=45)
plt.show()

# B∆∞·ªõc 1 : X·ª≠ l√Ω Missing Values (Thay 0 b·∫±ng NaN v√† Impute)
# ---------------------------------------------------------
cols_with_zero = ["Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI"]
data[cols_with_zero] = data[cols_with_zero].replace(0, np.nan)
# Chu·∫©n h√≥a t·∫°m ƒë·ªÉ KNN t√≠nh kho·∫£ng c√°ch ƒë√∫ng
scaler_for_impute = StandardScaler()
scaled_cols = scaler_for_impute.fit_transform(data[cols_with_zero])
# ƒêi·ªÅn d·ªØ li·ªáu khuy·∫øt
imputer = KNNImputer(n_neighbors=7)
imputed_scaled = imputer.fit_transform(scaled_cols)
# Tr·∫£ l·∫°i gi√° tr·ªã th·ª±c (Inverse)
data[cols_with_zero] = scaler_for_impute.inverse_transform(imputed_scaled)

# B∆Ø·ªöC 2: Feature Engineering (T·∫°o feature m·ªõi tr√™n d·ªØ li·ªáu ƒê√É S·∫†CH)
# L√∫c n√†y Glucose v√† BMI ƒë√£ ƒë·∫ßy ƒë·ªß s·ªë li·ªáu, ph√©p chia s·∫Ω lu√¥n ra s·ªë th·ª±c
print("Creating new features...")
data['Glucose_BMI_Ratio'] = data['Glucose'] / (data['BMI'] + 1e-5)
data['BloodPressure_Age_Interaction'] = data['BloodPressure'] * data['Age'] / 100
data['Insulin_Glucose_Ratio'] = data['Insulin'] / (data['Glucose'] + 1e-5)
data['Metabolic_Age_Index'] = data['BMI'] * data['Age'] / 100
data['Pregnancy_Age_Risk'] = data['Pregnancies'] * data['Age'] / 100

# B∆Ø·ªöC 3: X·ª≠ l√Ω Outlier (Tr√™n d·ªØ li·ªáu ƒë√£ ƒë·∫ßy ƒë·ªß v√† c√≥ feature m·ªõi)
# ---------------------------------------------------------
def remove_outlier_robust(df, col):
    if col in ["Insulin", "SkinThickness", "DiabetesPedigreeFunction"]: # C√≥ th·ªÉ gi·ªØ l·∫°i ho·∫∑c x·ª≠ l√Ω t√πy √Ω
        return df
    Q1 = df[col].quantile(0.10)
    Q3 = df[col].quantile(0.90)
    IQR = Q3 - Q1
    lower = Q1 - 3.0 * IQR
    upper = Q3 + 3.0 * IQR
    df[col] = df[col].clip(lower, upper)
    return df
# √Åp d·ª•ng cho c·∫£ c·ªôt c≈© v√† c·ªôt m·ªõi t·∫°o
for c in data.columns.drop('Outcome'):
    data = remove_outlier_robust(data, c)

# B∆Ø·ªöC 4: T√°ch, SMOTE v√† Chu·∫©n h√≥a cu·ªëi c√πng
# ---------------------------------------------------------
X = data.drop('Outcome', axis=1)
y = data['Outcome']

smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)
scaler_final = StandardScaler()
X_scaled = scaler_final.fit_transform(X_resampled)

# Chia t·∫≠p d·ªØ li·ªáu (Train / Val / Test)
X_temp, X_test, y_temp, y_test = train_test_split(
    X_scaled, y_resampled, test_size=0.15, random_state=42, stratify=y_resampled)
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp)

print(f"Data ready. Train: {X_train.shape[0]}, Val: {X_val.shape[0]}, Test: {X_test.shape[0]}")

# 2. HU·∫§N LUY·ªÜN LOGISTIC REGRESSION & V·∫º LEARNING CURVE
print("TRAINING BASE LOGISTIC REGRESSION (WITH HISTORY)...")

# C·∫•u h√¨nh model ƒë·ªÉ h·ªó tr·ª£ b∆∞·ªõc l·∫∑p th·ªß c√¥ng (warm_start)
base_lr_model = LogisticRegression(
    random_state=42,
    solver='saga',      
    warm_start=True,    
    max_iter=1,         # Ch·ªâ ch·∫°y 1 epoch m·ªói l·∫ßn g·ªçi fit
    C=1.0               
)
cost_train_hist, cost_val_hist = [], []
acc_train_hist, acc_val_hist = [], []
n_iterations = 200

# V√≤ng l·∫∑p hu·∫•n luy·ªán
for i in range(n_iterations):
    base_lr_model.fit(X_train, y_train)
    
    # Ghi l·∫°i Cost (Log Loss)
    train_proba = base_lr_model.predict_proba(X_train)
    val_proba = base_lr_model.predict_proba(X_val)
    cost_train_hist.append(log_loss(y_train, train_proba))
    cost_val_hist.append(log_loss(y_val, val_proba))
    
    # Ghi l·∫°i Accuracy
    acc_train_hist.append(base_lr_model.score(X_train, y_train))
    acc_val_hist.append(base_lr_model.score(X_val, y_val))

# 3. ƒê√ÅNH GI√Å V√Ä V·∫º BI·ªÇU ƒê·ªí

# D·ª± ƒëo√°n cu·ªëi c√πng
y_val_pred = base_lr_model.predict(X_val)
y_val_prob = base_lr_model.predict_proba(X_val)[:, 1]

# T√≠nh to√°n metrics
lr_acc = accuracy_score(y_val, y_val_pred)
lr_f1 = f1_score(y_val, y_val_pred)
lr_pre = precision_score(y_val, y_val_pred)
lr_rec = recall_score(y_val, y_val_pred)
lr_auc = roc_auc_score(y_val, y_val_prob)

print(f"Final Results (Iteration {n_iterations}):")
print(f"Accuracy  : {lr_acc:.4f}")
print(f"F1-Score  : {lr_f1:.4f}")
print(f"ReCall    : {lr_rec:.4f}")
print(f"Precision : {lr_pre:.4f}")
print(f"AUC       : {lr_auc:.4f}")

# V·∫Ω Learning Curve
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(cost_train_hist, label="Train Cost", color='blue')
plt.plot(cost_val_hist, label="Validation Cost", color='orange')
plt.xlabel("Iterations")
plt.ylabel("Cost (Log Loss)")
plt.title("Learning Curve - Cost")
plt.legend()
plt.grid(True)

plt.subplot(1, 2, 2)
plt.plot(acc_train_hist, label="Train Accuracy", color='blue')
plt.plot(acc_val_hist, label="Validation Accuracy", color='orange')
plt.xlabel("Iterations")
plt.ylabel("Accuracy")
plt.title("Learning Curve - Accuracy")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# V·∫Ω Confusion Matrix
cm = confusion_matrix(y_val, y_val_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Kh√¥ng m·∫Øc", "M·∫Øc"])
disp.plot(cmap="Blues")
plt.title("Confusion Matrix - Validation set")
plt.show()

# 4. T·ªêI ∆ØU H√ìA THRESHOLD (TƒÇNG RECALL)

print("\n" + "="*50)
print(" OPTIMIZING THRESHOLD FOR HIGH RECALL (F2-SCORE)")
print("="*50)

def find_best_threshold_f2(y_true, y_prob):
    """
    T√¨m threshold t·ªëi ∆∞u ƒë·ªÉ t·ªëi ƒëa h√≥a F2-Score 
    (∆Øu ti√™n Recall cao h∆°n Precision)
    """
    thresholds = np.arange(0.3, 1.0, 0.01)
    f2_scores = []
    recalls = []
    precisions = []
    
    for t in thresholds:
        y_pred_t = (y_prob >= t).astype(int)
        # F2 score: Beta = 2 nghƒ©a l√† coi tr·ªçng Recall g·∫•p 2 l·∫ßn Precision
        score = fbeta_score(y_true, y_pred_t, beta=2, zero_division=0)
        f2_scores.append(score)
        recalls.append(recall_score(y_true, y_pred_t, zero_division=0))
        precisions.append(precision_score(y_true, y_pred_t, zero_division=0))
        
    best_idx = np.argmax(f2_scores)
    return thresholds[best_idx], f2_scores[best_idx], recalls[best_idx], precisions[best_idx]

# T√¨m threshold t·ªët nh·∫•t
best_thresh, best_f2, best_rec, best_pre = find_best_threshold_f2(y_val, y_val_prob)

print(f"Optimal Threshold (F2) : {best_thresh:.4f}")
print(f"Best F2-Score          : {best_f2:.4f}")
print(f"Recall at new thresh   : {best_rec:.4f}")
print(f"Precision at new thresh: {best_pre:.4f}")

# √Åp d·ª•ng Threshold m·ªõi ƒë·ªÉ d·ª± ƒëo√°n l·∫°i
y_val_pred_new = (y_val_prob >= best_thresh).astype(int)

# So s√°nh k·∫øt qu·∫£
print("\n--- SO S√ÅNH HI·ªÜU QU·∫¢ ---")
print(f"Recall c≈© (Thresh=0.5)    : {lr_rec:.4f}")
print(f"Recall m·ªõi (Thresh={best_thresh:.2f}): {best_rec:.4f} (TƒÉng kh·∫£ nƒÉng ph√°t hi·ªán b·ªánh)")

# V·∫Ω Confusion Matrix m·ªõi
cm_new = confusion_matrix(y_val, y_val_pred_new)

plt.figure(figsize=(12, 5))  

# Ma tr·∫≠n c≈©
plt.subplot(1, 2, 1)
disp_old = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Kh√¥ng m·∫Øc", "M·∫Øc"])
disp_old.plot(cmap="Blues", ax=plt.gca(), colorbar=False)
plt.title(f"Threshold = 0.5\n(Missed: {cm[1,0]} cases)") # FN l√† d√≤ng 2 c·ªôt 1

# Ma tr·∫≠n m·ªõi
plt.subplot(1, 2, 2)
disp_new = ConfusionMatrixDisplay(confusion_matrix=cm_new, display_labels=["Kh√¥ng m·∫Øc", "M·∫Øc"])
disp_new.plot(cmap="Greens", ax=plt.gca(), colorbar=False)
plt.title(f"Threshold = {best_thresh:.4f}\n(Missed: {cm_new[1,0]} cases)")
plt.tight_layout()
plt.show()

"""# ENSEMBLE MODEL V·ªöI HYPERPARAMETER TUNING"""

# ƒê·ªãnh nghƒ©a c√°c models
models = {
    'Random Forest': RandomForestClassifier(random_state=42),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42),
    'SVM': SVC(probability=True, random_state=42)
}

# Hyperparameter grids
param_grids = {
    
    'Random Forest': {
        'n_estimators': [100, 200, 300],
        'max_depth': [10, 20, None],
        'min_samples_split': [2, 5, 10]
    },
    'Gradient Boosting': {
        'n_estimators': [100, 200],
        'learning_rate': [0.05, 0.1, 0.15],
        'max_depth': [3, 4, 5]
    },
    'SVM': {
        'C': [0.1, 1, 10],
        'kernel': ['rbf', 'linear'],
        'gamma': ['scale', 'auto']
    }
}

print(" Training and tuning models...")

best_models = {}
best_scores = {}

for name, model in models.items():
    print(f"\n Tuning {name}...")
    grid_search = GridSearchCV(
        model, param_grids[name], 
        cv=5, scoring='accuracy', n_jobs=-1, verbose=0
    )
    grid_search.fit(X_train, y_train)
    best_models[name] = grid_search.best_estimator_
    best_scores[name] = grid_search.best_score_

    print(f"Best params: {grid_search.best_params_}")
    print(f"Best CV score: {grid_search.best_score_:.4f}")

# Hi·ªÉn th·ªã k·∫øt qu·∫£ tuning
print("HYPERPARAMETER TUNING RESULTS")
for name, score in best_scores.items():
    print(f"{name:20}: {score:.4f}")

# T·∫°o Ensemble Model
print("\n Creating Ensemble Model...")

voting_clf = VotingClassifier(
    estimators=[
        ('rf', best_models['Random Forest']), 
        ('gb', best_models['Gradient Boosting']),
        ('svm', best_models['SVM'])
    ],
    voting='soft'
)
voting_clf.fit(X_train, y_train)

"""# üìà ƒê√ÅNH GI√Å M√î H√åNH"""

def evaluate_model(model, X, y, model_name="Model"):
    """ƒê√°nh gi√° to√†n di·ªán m√¥ h√¨nh"""
    y_pred = model.predict(X)
    y_prob = model.predict_proba(X)[:, 1] if hasattr(model, "predict_proba") else None
    
    acc = accuracy_score(y, y_pred)
    f1 = f1_score(y, y_pred)
    pre = precision_score(y, y_pred)
    rec = recall_score(y, y_pred)
    
    print(f"\n{model_name} Results:")
    print(f"Accuracy : {acc:.4f}")
    print(f"F1-Score : {f1:.4f}")
    print(f"Precision: {pre:.4f}")
    print(f"Recall   : {rec:.4f}")
    
    if y_prob is not None:
        auc_score = roc_auc_score(y, y_prob)
        print(f"AUC      : {auc_score:.4f}")
    
    # Confusion Matrix
    cm = confusion_matrix(y, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Kh√¥ng m·∫Øc", "M·∫Øc"])
    disp.plot(cmap="Blues")
    plt.title(f"Confusion Matrix - {model_name}")
    plt.show()
    
    
    return acc, f1, pre, rec

# ƒê√°nh gi√° t·∫•t c·∫£ models
print("üìà MODEL EVALUATION ON VALIDATION SET")
print("="*60)

val_results = {}
for name, model in best_models.items():
    print(f"\n--- {name} ---")
    acc, f1, pre, rec = evaluate_model(model, X_val, y_val, name)
    val_results[name] = {'accuracy': acc, 'f1': f1, 'precision': pre, 'recall': rec}

# ƒê√°nh gi√° Ensemble
print("\n--- ENSEMBLE MODEL ---")
ensemble_acc, ensemble_f1, ensemble_pre, ensemble_rec = evaluate_model(
    voting_clf, X_val, y_val, "Ensemble"
)
val_results['Ensemble'] = {
    'accuracy': ensemble_acc, 
    'f1': ensemble_f1, 
    'precision': ensemble_pre, 
    'recall': ensemble_rec
}

# So s√°nh k·∫øt qu·∫£
print("\n" + "="*60)
print("MODEL COMPARISON - VALIDATION SET")
print("="*60)
results_df = pd.DataFrame(val_results).T
results_df = results_df.sort_values('accuracy', ascending=False)
print(results_df.round(4))

# Ch·ªçn model t·ªët nh·∫•t
best_model_name = results_df.index[0]
best_model = voting_clf if best_model_name == 'Ensemble' else best_models[best_model_name]

print(f"\n BEST MODEL: {best_model_name}")
print(f" Validation Accuracy: {results_df.loc[best_model_name, 'accuracy']:.4f}")

"""#  ƒê√ÅNH GI√Å TR√äN TEST SET & T√åM THRESHOLD T·ªêI ∆ØU"""

# ƒê√°nh gi√° tr√™n test set v·ªõi model t·ªët nh·∫•t
print(" FINAL EVALUATION ON TEST SET")

# D·ª± ƒëo√°n probabilities
y_test_prob = best_model.predict_proba(X_test)[:, 1]

# T√¨m threshold t·ªëi ∆∞u b·∫±ng Youden's Index
fpr, tpr, thresholds = roc_curve(y_test, y_test_prob)
youden_j = tpr + (1 - fpr) - 1
best_idx = np.argmax(youden_j)
best_threshold = thresholds[best_idx]

print(f"Optimal threshold: {best_threshold:.4f}")

# ƒê√°nh gi√° v·ªõi threshold t·ªëi ∆∞u
y_test_pred_opt = (y_test_prob >= best_threshold).astype(int)

# T√≠nh metrics
test_acc = accuracy_score(y_test, y_test_pred_opt)
test_f1 = f1_score(y_test, y_test_pred_opt)
test_pre = precision_score(y_test, y_test_pred_opt)
test_rec = recall_score(y_test, y_test_pred_opt)
test_auc = roc_auc_score(y_test, y_test_prob)

print(f"\nTEST SET RESULTS (Threshold = {best_threshold:.4f})")
print(f"Accuracy : {test_acc:.4f}")
print(f"F1-Score : {test_f1:.4f}")
print(f"Precision: {test_pre:.4f}")
print(f"Recall   : {test_rec:.4f}")
print(f"AUC      : {test_auc:.4f}")

# Confusion Matrix
cm = confusion_matrix(y_test, y_test_pred_opt)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Kh√¥ng m·∫Øc", "M·∫Øc"])
disp.plot(cmap="Blues")
plt.title(f"Final Test Set - {best_model_name}\nAccuracy: {test_acc:.4f}")
plt.show()

# Feature Importance (n·∫øu c√≥)
if hasattr(best_model, 'feature_importances_'):
    feature_importance = pd.DataFrame({
        'feature': data.columns.drop('Outcome'),
        'importance': best_model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    plt.figure(figsize=(10, 6))
    sns.barplot(data=feature_importance, x='importance', y='feature')
    plt.title('Feature Importance')
    plt.tight_layout()
    plt.show()
    
    print("\nTOP 10 FEATURES BY IMPORTANCE:")
    print(feature_importance.head(10))
# So s√°nh v·ªõi baseline (threshold = 0.5)
y_test_pred_base = (y_test_prob >= 0.5).astype(int)
base_acc = accuracy_score(y_test, y_test_pred_base)
print(f"\nIMPROVEMENT COMPARISON:")
print(f"Baseline (threshold=0.5)  : {base_acc:.4f}")
print(f"Optimized (threshold={best_threshold:.4f}): {test_acc:.4f}")
print(f"Improvement               : +{(test_acc - base_acc):.4f}")
print("FINAL RESULTS SUMMARY")
print(f"\n Best Model: {best_model_name}")
print(f"Optimal Threshold: {best_threshold:.4f}")
print(f"AUC Score: {test_auc:.4f}")

# 5. TRI·ªÇN KHAI D·ª∞ ƒêO√ÅN (S·ª¨ D·ª§NG LOGISTIC REGRESSION

def prepare_patient_data(input_dict=None):
    """
    Tr·∫£ v·ªÅ vector features (8 g·ªëc + 5 feature m·ªõi).
    - N·∫øu input_dict = None ‚Üí nh·∫≠p t·ª´ b√†n ph√≠m
    - N·∫øu input_dict != None ‚Üí d√πng d·ªØ li·ªáu truy·ªÅn v√†o (fake)
    """

    ranges = {
        "Pregnancies": (0, 17),
        "Glucose": (44, 199),
        "BloodPressure": (24, 122),
        "SkinThickness": (7, 99),
        "Insulin": (14, 846),
        "BMI": (18.2, 67.1),
        "DiabetesPedigreeFunction": (0.078, 2.42),
        "Age": (21, 81)
    }

    features = []

    for feature in X.columns[:8]:  # 8 c·ªôt g·ªëc
        low, high = ranges[feature]

        if input_dict is None:
            # nh·∫≠p t·ª´ b√†n ph√≠m
            while True:
                try:
                    value = float(input(f"{feature} ({low}-{high}): "))
                    if low <= value <= high:
                        features.append(value)
                        break
                    else:
                        print(f"N·∫±m ngo√†i kho·∫£ng {low}-{high}. Nh·∫≠p l·∫°i!")
                except:
                    print("Vui l√≤ng nh·∫≠p s·ªë h·ª£p l·ªá!")
        else:
            # d√πng d·ªØ li·ªáu fake
            value = input_dict[feature]
            features.append(value)

    # T·ª± t·∫°o feature m·ªõi
    Glucose = features[X.columns.get_loc("Glucose")]
    BMI = features[X.columns.get_loc("BMI")]
    BloodPressure = features[X.columns.get_loc("BloodPressure")]
    Age = features[X.columns.get_loc("Age")]
    Insulin = features[X.columns.get_loc("Insulin")]
    Preg = features[X.columns.get_loc("Pregnancies")]

    new_features = [
        Glucose / (BMI + 1e-5),
        BloodPressure * Age / 100,
        Insulin / (Glucose + 1e-5),
        BMI * Age / 100,
        Preg * Age / 100
    ]

    full_features = np.array(features + new_features).reshape(1, -1)
    return full_features
def predict_patient_logistic(model, scaler, full_features, threshold=0.32):
    """
    D·ª± ƒëo√°n s·ª≠ d·ª•ng m√¥ h√¨nh Logistic Regression v·ªõi ng∆∞·ª°ng t·ªëi ∆∞u.
    """
    # 1. Chu·∫©n h√≥a d·ªØ li·ªáu (S·ª≠ d·ª•ng scaler ƒë√£ fit t·ª´ t·∫≠p train)
    scaled_features = scaler.transform(full_features)
    
    # 2. D·ª± ƒëo√°n x√°c su·∫•t (L·∫•y x√°c su·∫•t c·ªßa l·ªõp 1 - M·∫Øc b·ªánh)
    prob = model.predict_proba(scaled_features)[0][1]
    
    # 3. So s√°nh v·ªõi ng∆∞·ª°ng (Threshold 0.32 t·ªëi ∆∞u cho Recall)
    pred = 1 if prob >= threshold else 0

    # 4. In k·∫øt qu·∫£
    print("K·∫æT QU·∫¢ CH·∫®N ƒêO√ÅN (LOGISTIC REGRESSION)")
    print(f"X√°c su·∫•t m·∫Øc b·ªánh d·ª± t√≠nh: {prob:.4f} ({prob*100:.2f}%)")
    print(f"Ng∆∞·ª°ng quy·∫øt ƒë·ªãnh (Recall): {threshold}")
    
    if pred == 1:
        print("K·∫æT LU·∫¨N: C√ì NGUY C∆† M·∫ÆC TI·ªÇU ƒê∆Ø·ªúNG")
        print("   (Khuy·∫øn ngh·ªã: C·∫ßn ƒëi kh√°m chuy√™n s√¢u ngay)")
    else:
        print("K·∫æT LU·∫¨N: AN TO√ÄN (Nguy c∆° th·∫•p)")
    
    return pred, prob

# CH·∫†Y TH·ª¨ NGHI·ªÜM

# D·ªØ li·ªáu m·∫´u 1 (Ng∆∞·ªùi tr·∫ª, ch·ªâ s·ªë b√¨nh th∆∞·ªùng)
sample1 = {
    "Pregnancies": 1, "Glucose": 85, "BloodPressure": 66,
    "SkinThickness": 29, "Insulin": 0, "BMI": 26.6,
    "DiabetesPedigreeFunction": 0.351, "Age": 31
}

# D·ªØ li·ªáu m·∫´u 2 (Ng∆∞·ªùi trung ni√™n, ch·ªâ s·ªë cao - Nguy c∆° cao)
sample2 = {
    "Pregnancies": 5, "Glucose": 166, "BloodPressure": 72,
    "SkinThickness": 19, "Insulin": 175, "BMI": 35.8, # BMI cao
    "DiabetesPedigreeFunction": 0.587, "Age": 51
}

# 1. D·ª± ƒëo√°n Sample 1
print("Testing Sample 1...")
data1 = prepare_patient_data(sample1)
# L∆∞u √Ω: Truy·ªÅn base_lr_model v√† threshold t·ªëi ∆∞u c·ªßa Logistic Regression
predict_patient_logistic(base_lr_model, scaler_final, data1, threshold=0.3)

# 2. D·ª± ƒëo√°n Sample 2
print("Testing Sample 2...")
data2 = prepare_patient_data(sample2)
predict_patient_logistic(base_lr_model, scaler_final, data2, threshold=0.3)
# 3 . nhap v√†o
dattta = prepare_patient_data()
predict_patient_logistic(base_lr_model,scaler_final,dattta,  threshold=0.3)